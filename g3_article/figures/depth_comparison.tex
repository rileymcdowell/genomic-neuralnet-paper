
\begin{figure}[htbp]
\renewcommand{\familydefault}{\sfdefault}\normalfont
\centering 
\includegraphics[width=\linewidth]{g3_article/figures/depth_comparison.png}
    \caption{Distribution of predictive accuracy by benchmark dataset, network depth, 
             and model. The violin plot width indicates the Kernel Density Estimate 
             (KDE) of all observed accuraies of all models at a given network depth. 
             The sample size of the KDE depends on the number of model hyper 
             parameters evaluated. For model N, there are no hyper 
             parameters beyond the seven network archetectures selected for each depth. 
             For models NWD and NDO, there are an additional four weight decay and dropout 
             parameters evaluated, respectively. For model NWDDO, there are 16 (all combinations 
             of four weight decay and four dropout parameters). In summary, the KDE 
             plots are constructed from either 7, 28, or 112 samples. 
             The models contributing to each KDE vary across one or more 
             of their weight decay, dropout, and hidden layer parameters and can be 
             understood as the distribution of results across the set of 
             hyper-parameters to all network models with the same depth and regularization
             type. The KDE bandwidth parameters are set using Scott's normal reference rule. 
             Negative accuraies are the result of trained models producing predictions that 
             are negatively correlated with actual measurements. The KDE plots are 
             trucated to the minimum and maximum observed prediction accuracies. The 
             highest mean performing model's shape is listed above each KDE plot as a 
             example of a highly effective network archetecture for that particular dataset, 
             network type, and hidden layer size.} 
\label{fig:depth-comparison}
\end{figure}

