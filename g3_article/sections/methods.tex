Three benchmark datasets of paired phenotypic and genotypic marker data were predicted 
using a collection of regression techniques. Three food crops were selected
as benchmark species. Benchmark traits included both high and low heritability 
traits with simple and complex genetic architectures. Each dataset was divided
into five partitions by drawing entries without replacement and predicted with each
regression technique using five-fold cross validation. This process was then repeated
a second time to produce 10 randomized predictions for each regression technique on
each dataset and trait. The partitions of the data were held constant across all 
regression techniques to facilitate a fair comparison of the prediction accuracy of 
each technique.

For statistical models with tunable hyperparameters, a grid-search of the parameter 
space was conducted and the parameters as well as mean and standard deviation of
prediction accuracies for each parameter combination was recorded. 

On occasion, we observed neural network outputs diverging to negative or positive infinity rather
than a global or local optimum prediction. This can happen when the weights and biases of the 
hidden layer neurons are initialized very far from the optimum values. To reduce
the incidence of divergence, the first hundred epochs of neural network training
were repeated twice, and the model with the lowest prediction error at that time was selected
to continue training. This was found to eliminate divergent predictions.

The full analysis pipeline, including formatted datasets, quality control processes, 
implementations of each model, and final hyperparameter settings in file databases 
are available in versioned files in a public repository on github \citep{mcdowell2016}.

\subsection*{Statistical Analysis} 

Least squares, ridge, lasso, and elastic net regression were applied as examples of
linear regression with and without normalization penalties. Bayesian 
ridge regression is a bayesian version of ridge regression that assumes that 
the residual error in the model is gaussian distributed. These five regression 
techniques are implemented in the scikit-learn python package version 0.17.1 \citep{scikit-learn}.

A single parameterized neural network with dropout and weight-decay parameters was built using 
the Keras modular neural network library \citep{chollet2015}. The neural network results presented in this
manuscript were trained and evaluated using the default Theano backend \citep{team2016}. 
Network training was conducted on a combination of a single NVIDIA GTX 680 graphics card with 4GB 
of RAM and a cluster of NVIDIA GRID K520 graphics cards with 4GB of ram. Both cards used the 
CUDA 7.5 toolkit \citep{nickolls2008}. A network with no regularization,
as well as with either one or both of the weight-decay and dropout regularization parameters
supplied was trained on each dataset. A summary of all regression methods is presented 
in Table \ref{tab:regression-methods}.

\ifdefined\showtablesandfigures
\input{g3_article/tables/regression_methods} % Label = tab:regression-methods.
\fi

Each regression technique was trained and evaluated on each phenotypic trait in all ten (5*2) cross-validation 
folds of each dataset. The correlation of the predicted and actual phenotypic values was taken for each fold, and the average and 
standard deviation of the resulting correlation coefficients for each regression technique were reported.

\subsection*{Benchmark Datasets}

Arabidopsis, maize, and wheat datasets were collected from the author's web pages
or the supplementary information published with their respective papers \citep{loudet2002, crossa2010, thavamanikumar2015}.
Species, authorship, marker, and sample information is summarized in Table \ref{tab:benchmark-datasets}.

\ifdefined\showtablesandfigures
\input{g3_article/tables/benchmark_datasets} % Label = tab:benchmark-datasets.
\fi

Marker calls were scaled to the range $[0,1]$ for all SNP information. If more than 20\% of
marker calls were missing for a sample, the sample was discarded. If fewer than 20\% were missing,
the average value for that marker was imputed for the missing values with one exception: if data were 
published with a marker imputation technique already applied, no further imputation was attempted.

Individuals without phenotypic measurements were discarded from further analysis. A combination of phenotypic 
measurements and deregressed breeding values were predicted, depending on which measure was provided by the authors.

In addition to their original publications, copies of each of the benchmark datasets as well 
as modified versions formatted for compatibility with the analyses presented in 
this paper are available on github \citep{mcdowell2016}. The analysis framework 
is extensible and can be utilized to evaluate arbitrary datasets and predictive models
with minimal coding requirements provided the statistical models are implemented
in the python2.7 programming language.

